首先是背景这一块
口令复用现象普遍，然后一方面是讲hashcat这种静态规则库局限、容易复杂度爆炸；一方面讲其他的口令猜测的模型

主要是把模型的架构讲清楚


实验这一块：
+ 不同训练集大小的影响（正在做）
+ 对于qwen3模型而言，不同参数量的影响（已做）
+ 对于llama模型而言，不同参数量的影响（未做）和qwen的放一起对比
+ 训练不同学习率的影响（针对Qwen3 1.7b），要补充
+ 训练采用的提示词（针对Qwen3 1.7b），要补充
+ 撞库实验，验证即使多口令也有用，要补充
+ 如果有空再补一个跨站攻击，不过不必须
+ 或许还有不同生成方式的影响？
+ 对了还有其他模型的对比，目前能做的是Pass2path、Targauss/PCFG?OMEN? or passgpt https://github.com/javirandor/passgpt

